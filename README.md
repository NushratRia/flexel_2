

---

### âœ… `Flexel

```markdown

This project is a **Flask-based web application** that allows users to view and interact with Google Sheets using traditional input, voice commands, and hand gestures (via webcam). It combines:

- âœ… Handsontable for dynamic spreadsheet rendering
- âœ… Voice input using Web Speech API + OpenAI Whisper API
- âœ… Hand gesture recognition using MediaPipe Hands
- âœ… Modular gesture control (17+ gestures supported)
- âœ… Google OAuth integration for authorized saving

---

## ğŸ“ Project Structure

```

â”œâ”€â”€ app.py                     # Flask backend
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html             # Home page for pasting Google Sheet URL
â”‚   â””â”€â”€ view\.html              # Sheet viewer with gesture + voice UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ gestureController.js
â”‚       â”œâ”€â”€ gestureHighlight\_debug.js
â”‚       â”œâ”€â”€ pinchSelect.js
â”‚       â”œâ”€â”€ voicechat.js
â”‚       â””â”€â”€ ... (more gestures)
â”œâ”€â”€ rebuild.json               # OAuth client secrets
â”œâ”€â”€ .env                       # API keys and Flask secret
â””â”€â”€ README.md                  # You're here

````

---

## ğŸš€ How It Works

### 1. **Google Sheet Import**
- User pastes a public or shared Google Sheet URL.
- The app converts it into a downloadable CSV format and renders it via Handsontable.

### 2. **Voice Interaction**
- Web Speech API for live transcription.
- Optionally integrates OpenAI Whisper API for better transcription.
- Chatbox shows real-time transcript log.

### 3. **Gesture Interaction**
- Uses webcam + MediaPipe Hands in-browser (no server-side CV).
- Supports:
  - Highlighting cells, rows, columns
  - Pinch-to-select
  - Zooming in/out
  - Scroll gestures
  - Modular extension for custom gestures

---

## ğŸ§  Setup Instructions

### 1. ğŸ“¦ Install Python dependencies
```bash
pip install -r requirements.txt
# or manually
pip install flask python-dotenv google-auth google-auth-oauthlib google-api-python-client
````

### 2. ğŸ” Set up `.env`

Create a `.env` file:

```
FLASK_SECRET_KEY=your_secret_here
API_KEY=your_google_api_key
```

Place your Google OAuth client in:

```
rebuild.json
```

### 3. â–¶ï¸ Run the Flask app

```bash
python app.py
```

Go to `http://localhost:5000`

---

## ğŸŒ Frontend Features

* `view.html` is the main interface
* `<video>` and `<canvas>` overlay used for hand tracking
* Modular gesture system in `/static/js/` using `setupGestureXYZ()` functions
* `voicechat.js` handles Web Speech recognition and log display

---

## âœ‹ Adding New Gestures

Add a new JS file in `/static/js/`:

```js
export function setupTwoFingerDrag(hands, canvasElement, canvasCtx) {
  hands.onResults(results => {
    // Gesture logic
  });
}
```

Then register it in `gestureController.js`:

```js
import { setupTwoFingerDrag } from './twoFingerDrag.js';
setupTwoFingerDrag(hands, canvas, ctx);
```

---

## ğŸ” Google OAuth (optional)

* Sign in via `/authorize`
* Authenticated users can autosave back to their own Google Sheet
* Uses Google Sheets + Drive APIs

---

## ğŸ—‚ Handsontable Customizations

* Freeze headers
* Resize/drag/drop columns
* Inline editing
* Filter + sort support
* CSV export

---

## ğŸ“¸ Dependencies

* [MediaPipe Hands](https://google.github.io/mediapipe/)
* [Handsontable](https://handsontable.com/)
* [OpenAI Whisper API (optional)](https://platform.openai.com/docs/guides/speech-to-text)
* [Flask](https://flask.palletsprojects.com/)

---

## ğŸ§ª Debug Tips

* Gesture logs go to `console` + can be sent to `app.log`
* You can test with `combined_sheet.xlsx` if offline
* Use browser devtools to inspect `.gesture-highlight`, `.gesture-selected`

---

## ğŸ“„ License

MIT License. Free to use and extend for research, prototyping, or personal use.

---

> Built with â¤ï¸ to explore natural input interaction models: WIMP, Voice, and Gesture.

```

---

```
